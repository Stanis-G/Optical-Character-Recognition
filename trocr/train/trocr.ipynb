{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Stas\\anaconda3\\envs\\ocr_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from transformers import (\n",
    "    VisionEncoderDecoderModel,\n",
    "    TrOCRProcessor,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    get_cosine_with_hard_restarts_schedule_with_warmup,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "import torch\n",
    "import mlflow\n",
    "\n",
    "from train.utils_train import save_model_and_history, plot_history\n",
    "# from OCR_VQA.data_preparation import VQAProcessor\n",
    "from custom_dataset.data_preparation import CustomDataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/09 20:41:30 INFO mlflow.tracking.fluent: Experiment with name 'trocr_train' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/778888683745344032', creation_time=1744220490751, experiment_id='778888683745344032', last_update_time=1744220490751, lifecycle_stage='active', name='trocr_train', tags={}>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = 'trocr_train'\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiment.experiment_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>status</th>\n",
       "      <th>artifact_uri</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [run_id, experiment_id, status, artifact_uri, start_time, end_time]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrOCRProcessor class wraps image processor class and tokenizer class\n",
    "dataset_name = 'ocr-dataset'\n",
    "# dataset_name = os.path.join(project_root, 'custom_dataset', 'data', dataset_name) # For local dataset\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-small-printed\")\n",
    "\n",
    "\n",
    "data_processor = CustomDataProcessor(processor)\n",
    "train_dataset, val_dataset, test_dataset, train_size = data_processor(\n",
    "    dataset_type='S3', # change to 'local' for using local stored dataset\n",
    "    train_frac=0.95,\n",
    "    val_frac=0.025,\n",
    "    dataset_name=dataset_name,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VisionEncoderDecoderModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    }
   ],
   "source": [
    "# model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-small-printed\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"checkpoints/06.04.25_S3_100k_v2/checkpoint-10000\")\n",
    "\n",
    "# Choosing a strategy for text generation\n",
    "# All strategies can be found here: \n",
    "# https://huggingface.co/docs/transformers/v4.48.2/en/main_classes/text_generation#transformers.GenerationConfig\n",
    "\n",
    "gen_config = dict(\n",
    "    num_beams=7,\n",
    "    num_beam_groups=1,\n",
    "    do_sample=True,\n",
    "    max_new_tokens=200,\n",
    "    early_stopping=True, # True stops when num_beams candidates are reached\n",
    "    temperature=1.5, # T <(>) 1 sharpens (smoothes) probability distribution\n",
    "    top_k=100, # Only top k candidates with highest probabilities will be considered\n",
    "    diversity_penalty=0, # The value is substracted from beam score if the token is generated by another group\n",
    "    repetition_penalty=1.2, # AFAIK Directly multiplied by temperature\n",
    "    # decoder_start_token_id=processor.tokenizer.bos_token_id,\n",
    "    # pad_token_id=processor.tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "model.generation_config.update(**gen_config) # Update existing generation config with new values\n",
    "model.config.decoder_start_token_id = processor.tokenizer.bos_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "\n",
    "date = datetime.now().strftime(\"%d.%m.%y\")\n",
    "\n",
    "model_name = f'{date}_{dataset_name}_v1'\n",
    "\n",
    "output_dir = f'checkpoints/{model_name}'\n",
    "num_epochs = 10\n",
    "batch_size = 8\n",
    "init_learning_rate = 2.0e-6 #1e-5\n",
    "max_steps = int((train_size / batch_size) * num_epochs)\n",
    "eval_steps = logging_steps = 1000\n",
    "\n",
    "# Initialize the optimizer. See this for optimizers:\n",
    "# https://huggingface.co/docs/transformers/en/main_classes/optimizer_schedules\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=init_learning_rate)\n",
    "\n",
    "# Set up a learning rate scheduler. See this for scheduler types:\n",
    "# https://huggingface.co/docs/transformers/v4.49.0/en/main_classes/optimizer_schedules#transformers.SchedulerType\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(max_steps * 0), # % of the steps for warmup\n",
    "    num_training_steps=max_steps,\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStoppingCallback(early_stopping_patience=5)\n",
    "\n",
    "training_hyperparams = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    report_to='mlflow',\n",
    "    run_name=model_name, # for mlflow logging\n",
    "    # learning_rate=1e-4,\n",
    "    # lr_scheduler_type='linear', \n",
    "    eval_strategy='steps', # evaluate on eval_dataset every eval_steps\n",
    "    eval_steps=eval_steps,\n",
    "    eval_accumulation_steps=logging_steps,\n",
    "    logging_steps=logging_steps, # update steps to perform before output logs\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    # max_steps=max_steps, # Overrides num_train_epochs\n",
    "    save_total_limit=1, # Save only last checkpoint\n",
    "    load_best_model_at_end=True, # Save best model\n",
    "    metric_for_best_model='eval_loss', # Key from dict, returned by compute_metrics, or some predefined values\n",
    "    greater_is_better=False,\n",
    "    save_steps=10000,\n",
    "    # logging_dir='trocr_checkpoints/logs',\n",
    "    # fp16=True,\n",
    "    fp16_full_eval=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1000/118560 [09:58<24:48:53,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3108, 'grad_norm': 2.1685426235198975, 'learning_rate': 2.199613826365429e-06, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      "  1%|          | 1000/118560 [12:11<24:48:53,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24410735070705414, 'eval_runtime': 133.0535, 'eval_samples_per_second': 18.752, 'eval_steps_per_second': 2.345, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2000/118560 [21:51<18:28:01,  1.75it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3356, 'grad_norm': 3.756221055984497, 'learning_rate': 2.1984555766073082e-06, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      "  2%|▏         | 2000/118560 [24:04<18:28:01,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.263593852519989, 'eval_runtime': 132.5658, 'eval_samples_per_second': 18.821, 'eval_steps_per_second': 2.354, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3000/118560 [33:54<20:28:30,  1.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2588, 'grad_norm': 4.268790245056152, 'learning_rate': 2.1965260639720362e-06, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      "  3%|▎         | 3000/118560 [36:12<20:28:30,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2590153217315674, 'eval_runtime': 137.6969, 'eval_samples_per_second': 18.12, 'eval_steps_per_second': 2.266, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4000/118560 [46:25<21:41:21,  1.47it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3107, 'grad_norm': 2.8645238876342773, 'learning_rate': 2.1938266432358075e-06, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      "  3%|▎         | 4000/118560 [48:38<21:41:21,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.26178398728370667, 'eval_runtime': 133.611, 'eval_samples_per_second': 18.674, 'eval_steps_per_second': 2.335, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 5000/118560 [59:03<24:45:14,  1.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2806, 'grad_norm': 1.5622378587722778, 'learning_rate': 2.1903592097533803e-06, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      "  4%|▍         | 5000/118560 [1:01:27<24:45:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2603222727775574, 'eval_runtime': 144.2185, 'eval_samples_per_second': 17.3, 'eval_steps_per_second': 2.163, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 6000/118560 [1:11:17<21:29:30,  1.45it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3178, 'grad_norm': 4.393310546875, 'learning_rate': 2.186126198127283e-06, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \n",
      "  5%|▌         | 6000/118560 [1:13:49<21:29:30,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2639763057231903, 'eval_runtime': 151.4982, 'eval_samples_per_second': 16.469, 'eval_steps_per_second': 2.059, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 7000/118560 [1:24:29<23:54:49,  1.30it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2644, 'grad_norm': 1.710511565208435, 'learning_rate': 2.181130580498397e-06, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \n",
      "  6%|▌         | 7000/118560 [1:26:54<23:54:49,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2622835636138916, 'eval_runtime': 145.2707, 'eval_samples_per_second': 17.175, 'eval_steps_per_second': 2.148, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 8000/118560 [1:37:05<21:20:30,  1.44it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3103, 'grad_norm': 3.2963521480560303, 'learning_rate': 2.1753758644591165e-06, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \n",
      "  7%|▋         | 8000/118560 [1:39:34<21:20:30,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.26190298795700073, 'eval_runtime': 149.4012, 'eval_samples_per_second': 16.7, 'eval_steps_per_second': 2.088, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 9000/118560 [1:49:21<17:40:15,  1.72it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2306, 'grad_norm': 2.1879565715789795, 'learning_rate': 2.1688660905905485e-06, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \n",
      "  8%|▊         | 9000/118560 [1:51:28<17:40:15,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28553342819213867, 'eval_runtime': 127.6767, 'eval_samples_per_second': 19.542, 'eval_steps_per_second': 2.444, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 10000/118560 [2:02:31<24:43:06,  1.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3361, 'grad_norm': 1.6545602083206177, 'learning_rate': 2.161605829625483e-06, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \n",
      "  8%|▊         | 10000/118560 [2:05:11<24:43:06,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.25895318388938904, 'eval_runtime': 160.2443, 'eval_samples_per_second': 15.57, 'eval_steps_per_second': 1.947, 'epoch': 0.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 11000/118560 [2:18:00<24:53:03,  1.20it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3071, 'grad_norm': 3.4142446517944336, 'learning_rate': 2.15360017923913e-06, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \n",
      "  9%|▉         | 11000/118560 [2:20:43<24:53:03,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2567855417728424, 'eval_runtime': 162.7511, 'eval_samples_per_second': 15.33, 'eval_steps_per_second': 1.917, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 11113/118560 [2:22:05<19:48:53,  1.51it/s]  "
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_hyperparams,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        # preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "        # compute_metrics=compute_metrics,\n",
    "        optimizers=(optimizer, lr_scheduler),\n",
    "        callbacks=[early_stopping]\n",
    "        # processing_class=processor,\n",
    "        # data_collator=...\n",
    "    )\n",
    "    trainer.train()\n",
    "else:\n",
    "    raise ValueError(f\"Model '{model_name}' exists, specify another name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Save model and history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=model_name):\n",
    "\n",
    "    mlflow.transformers.log_model(trainer.model, artifact_path=model_name)\n",
    "    mlflow.log_params(training_hyperparams.to_dict())\n",
    "    metrics = trainer.evaluate()\n",
    "    mlflow.log_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_and_history(model_name, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Plot training history__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [i['epoch'] for i in trainer.state.log_history if 'eval_loss' in i]\n",
    "train_loss = [i['loss'] for i in trainer.state.log_history if 'loss' in i]\n",
    "val_loss = [i['eval_loss'] for i in trainer.state.log_history if 'eval_loss' in i]\n",
    "# val_cer = [10 * i['eval_cer'] for i in trainer.state.log_history if 'eval_cer' in i]\n",
    "\n",
    "hist = {'train_loss': train_loss, 'val_loss': val_loss}#, 'val_cer * 10': val_cer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_history(\n",
    "    epochs,\n",
    "    hist,\n",
    "    run_name=model_name,\n",
    "    figsize=(15, 10),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

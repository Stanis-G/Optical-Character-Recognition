{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from transformers import (\n",
    "    VisionEncoderDecoderModel,\n",
    "    TrOCRProcessor,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    get_cosine_with_hard_restarts_schedule_with_warmup,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    EarlyStoppingCallback,\n",
    "    pipeline,\n",
    ")\n",
    "import torch\n",
    "import mlflow\n",
    "\n",
    "from utils_train import save_model_and_history, plot_history\n",
    "# from OCR_VQA.data_preparation import VQAProcessor\n",
    "from custom_dataset.data_preparation import CustomDataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set mlflow experiment\n",
    "\n",
    "experiment_name = 'trocr_train'\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all runs\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "df_runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrOCRProcessor class wraps image processor class and tokenizer class\n",
    "dataset_name = 'ocr-dataset'\n",
    "# dataset_name = os.path.join(project_root, 'custom_dataset', 'data', dataset_name) # For local dataset\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-small-printed\")\n",
    "\n",
    "data_processor = CustomDataProcessor(processor)\n",
    "train_dataset, val_dataset, test_dataset, train_size = data_processor(\n",
    "    dataset_type='S3', # change to 'local' for using local stored dataset\n",
    "    train_frac=0.95,\n",
    "    val_frac=0.025,\n",
    "    dataset_name=dataset_name,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-small-printed\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"checkpoints/06.04.25_S3_100k_v2/checkpoint-10000\")\n",
    "\n",
    "# Choosing a strategy for text generation\n",
    "# All strategies can be found here: \n",
    "# https://huggingface.co/docs/transformers/v4.48.2/en/main_classes/text_generation#transformers.GenerationConfig\n",
    "\n",
    "gen_config = dict(\n",
    "    num_beams=7,\n",
    "    num_beam_groups=1,\n",
    "    do_sample=True,\n",
    "    max_new_tokens=200,\n",
    "    early_stopping=True, # True stops when num_beams candidates are reached\n",
    "    temperature=1.5, # T <(>) 1 sharpens (smoothes) probability distribution\n",
    "    top_k=100, # Only top k candidates with highest probabilities will be considered\n",
    "    diversity_penalty=0, # The value is substracted from beam score if the token is generated by another group\n",
    "    repetition_penalty=1.2, # AFAIK Directly multiplied by temperature\n",
    "    # decoder_start_token_id=processor.tokenizer.bos_token_id,\n",
    "    # pad_token_id=processor.tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "model.generation_config.update(**gen_config) # Update existing generation config with new values\n",
    "model.config.decoder_start_token_id = processor.tokenizer.bos_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give name to current run (model) and create it\n",
    "v = 1\n",
    "date = datetime.now().strftime(\"%d.%m.%y\")\n",
    "model_name = f'{date}_{dataset_name}_v{v}'\n",
    "if not df_runs.empty:\n",
    "    while (df_runs['params.run_name'] == model_name).any():\n",
    "        v += 1\n",
    "        model_name = f'{date}_{dataset_name}_v{v}'\n",
    "print(model_name)\n",
    "\n",
    "with mlflow.start_run(run_name=model_name) as run:\n",
    "    run_id = run.info.run_id\n",
    "os.environ['MLFLOW_RUN_ID'] = run_id\n",
    "print(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store run_name and run_id for downstream use\n",
    "\n",
    "%store run_id\n",
    "%store model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "\n",
    "output_dir = f'checkpoints/{model_name}'\n",
    "num_epochs = 1\n",
    "batch_size = 8\n",
    "init_learning_rate = 2.0e-6 #1e-5\n",
    "max_steps = int((train_size / batch_size) * num_epochs)\n",
    "eval_steps = logging_steps = 1000\n",
    "\n",
    "# Initialize the optimizer. See this for optimizers:\n",
    "# https://huggingface.co/docs/transformers/en/main_classes/optimizer_schedules\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=init_learning_rate)\n",
    "\n",
    "# Set up a learning rate scheduler. See this for scheduler types:\n",
    "# https://huggingface.co/docs/transformers/v4.49.0/en/main_classes/optimizer_schedules#transformers.SchedulerType\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(max_steps * 0), # % of the steps for warmup\n",
    "    num_training_steps=max_steps,\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStoppingCallback(early_stopping_patience=5)\n",
    "\n",
    "training_hyperparams = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    report_to='mlflow',\n",
    "    run_name=model_name, # for mlflow logging\n",
    "    # learning_rate=1e-4,\n",
    "    # lr_scheduler_type='linear', \n",
    "    eval_strategy='steps', # evaluate on eval_dataset every eval_steps\n",
    "    eval_steps=eval_steps,\n",
    "    eval_accumulation_steps=logging_steps,\n",
    "    logging_steps=logging_steps, # update steps to perform before output logs\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    # max_steps=max_steps, # Overrides num_train_epochs\n",
    "    save_total_limit=1, # Save only last checkpoint\n",
    "    load_best_model_at_end=True, # Save best model\n",
    "    metric_for_best_model='eval_loss', # Key from dict, returned by compute_metrics, or some predefined values\n",
    "    greater_is_better=False,\n",
    "    save_steps=10000,\n",
    "    # logging_dir='trocr_checkpoints/logs',\n",
    "    # fp16=True,\n",
    "    fp16_full_eval=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_hyperparams,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        # preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "        # compute_metrics=compute_metrics,\n",
    "        optimizers=(optimizer, lr_scheduler),\n",
    "        callbacks=[early_stopping]\n",
    "        # processing_class=processor,\n",
    "        # data_collator=...\n",
    "    )\n",
    "    trainer.train()\n",
    "else:\n",
    "    raise ValueError(f\"Model '{model_name}' exists, specify another name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Save model and history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap model and processor to pipeline to log into mlflow\n",
    "\n",
    "ocr_pipeline = pipeline(\n",
    "    \"image-to-text\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    device='cuda',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [i['epoch'] for i in trainer.state.log_history if 'eval_loss' in i]\n",
    "train_loss = [i['loss'] for i in trainer.state.log_history if 'loss' in i]\n",
    "val_loss = [i['eval_loss'] for i in trainer.state.log_history if 'eval_loss' in i]\n",
    "# val_cer = [10 * i['eval_cer'] for i in trainer.state.log_history if 'eval_cer' in i]\n",
    "\n",
    "hist = {'train_loss': train_loss, 'val_loss': val_loss}#, 'val_cer * 10': val_cer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create history plot\n",
    "\n",
    "fig = plot_history(\n",
    "    epochs,\n",
    "    hist,\n",
    "    run_name=model_name,\n",
    "    figsize=(15, 10),\n",
    "    to_image=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=model_name, run_id=run_id):\n",
    "\n",
    "    mlflow.transformers.log_model(ocr_pipeline, model_name)\n",
    "    mlflow.log_params(training_hyperparams.to_dict())\n",
    "    mlflow.log_image(image=fig, artifact_file=\"history.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

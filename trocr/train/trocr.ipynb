{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from transformers import (\n",
    "    VisionEncoderDecoderModel,\n",
    "    TrOCRProcessor,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    get_cosine_with_hard_restarts_schedule_with_warmup,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "import torch\n",
    "\n",
    "from utils_dev import save_model_and_history, evaluate_model, cer_score, plot_history\n",
    "from trocr.utils.utils_inf import inference\n",
    "# from OCR_VQA.data_preparation import VQAProcessor\n",
    "from custom_dataset.data_preparation import CustomDataProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrOCRProcessor class wraps image processor class and tokenizer class\n",
    "dataset_name = 'wiki_sentences_300k' # 'S3_100k'\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-small-printed\")\n",
    "data_path = os.path.join(project_root, 'custom_dataset', 'data', dataset_name)\n",
    "\n",
    "data_processor = CustomDataProcessor(processor)\n",
    "train_dataset, val_dataset, test_dataset, train_size = data_processor(\n",
    "    dataset_type='S3', # change to 'local' for using local stored dataset\n",
    "    train_frac=0.95,\n",
    "    val_frac=0.025,\n",
    "    bucket='ocr-dataset', # change param name to data_fold for using local stored dataset\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-small-printed\")\n",
    "\n",
    "# Choosing a strategy for text generation\n",
    "# All strategies can be found here: \n",
    "# https://huggingface.co/docs/transformers/v4.48.2/en/main_classes/text_generation#transformers.GenerationConfig\n",
    "\n",
    "gen_config = dict(\n",
    "    num_beams=7,\n",
    "    num_beam_groups=1,\n",
    "    do_sample=True,\n",
    "    max_new_tokens=200,\n",
    "    early_stopping=True, # True stops when num_beams candidates are reached\n",
    "    temperature=1.5, # T <(>) 1 sharpens (smoothes) probability distribution\n",
    "    top_k=100, # Only top k candidates with highest probabilities will be considered\n",
    "    diversity_penalty=0, # The value is substracted from beam score if the token is generated by another group\n",
    "    repetition_penalty=1.2, # AFAIK Directly multiplied by temperature\n",
    "    # decoder_start_token_id=processor.tokenizer.bos_token_id,\n",
    "    # pad_token_id=processor.tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "model.generation_config.update(**gen_config) # Update existing generation config with new values\n",
    "model.config.decoder_start_token_id = processor.tokenizer.bos_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "\n",
    "model_name = f'26.03.25_{dataset_name}'\n",
    "output_dir = f'checkpoints/{model_name}'\n",
    "num_epochs = 10\n",
    "batch_size = 8\n",
    "init_learning_rate = 1e-3\n",
    "max_steps = int((train_size / batch_size) * num_epochs)\n",
    "eval_steps = logging_steps = 1000\n",
    "\n",
    "# Initialize the optimizer. See this for optimizers:\n",
    "# https://huggingface.co/docs/transformers/en/main_classes/optimizer_schedules\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=init_learning_rate)\n",
    "\n",
    "# Set up a learning rate scheduler. See this for scheduler types:\n",
    "# https://huggingface.co/docs/transformers/v4.49.0/en/main_classes/optimizer_schedules#transformers.SchedulerType\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(max_steps * 0), # % of the steps for warmup\n",
    "    num_training_steps=max_steps,\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStoppingCallback(early_stopping_patience=5)\n",
    "\n",
    "training_hyperparams = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    # learning_rate=1e-4,\n",
    "    # lr_scheduler_type='linear', \n",
    "    eval_strategy='steps', # evaluate on eval_dataset every eval_steps\n",
    "    eval_steps=eval_steps,\n",
    "    eval_accumulation_steps=logging_steps,\n",
    "    logging_steps=logging_steps, # update steps to perform before output logs\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    # max_steps=max_steps, # Overrides num_train_epochs\n",
    "    save_total_limit=1, # Save only last checkpoint\n",
    "    load_best_model_at_end=True, # Save best model\n",
    "    metric_for_best_model='eval_loss', # Key from dict, returned by compute_metrics, or some predefined values\n",
    "    greater_is_better=False,\n",
    "    save_steps=10000,\n",
    "    # logging_dir='trocr_checkpoints/logs',\n",
    "    # fp16=True,\n",
    "    fp16_full_eval=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_hyperparams,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        # preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "        # compute_metrics=compute_metrics,\n",
    "        optimizers=(optimizer, lr_scheduler),\n",
    "        callbacks=[early_stopping]\n",
    "        # processing_class=processor,\n",
    "        # data_collator=...\n",
    "    )\n",
    "    trainer.train()\n",
    "else:\n",
    "    raise ValueError(f\"Model '{model_name}' exists, specify another name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Save model and history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_and_history(model_name, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation and Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Plot training history__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [i['epoch'] for i in trainer.state.log_history if 'eval_loss' in i]\n",
    "train_loss = [i['loss'] for i in trainer.state.log_history if 'loss' in i]\n",
    "val_loss = [i['eval_loss'] for i in trainer.state.log_history if 'eval_loss' in i]\n",
    "# val_cer = [10 * i['eval_cer'] for i in trainer.state.log_history if 'eval_cer' in i]\n",
    "\n",
    "hist = {'train_loss': train_loss, 'val_loss': val_loss}#, 'val_cer * 10': val_cer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(\n",
    "    epochs,\n",
    "    hist,\n",
    "    run_name=model_name,\n",
    "    figsize=(15, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Load model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'20.03.25_{dataset_name}'\n",
    "\n",
    "model_path = f'models/{model_name}/model'\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_pretrained(model_path)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Evaluate model on datasets__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, train_cer_value = evaluate_model(model, processor, train_dataset.dataset.indeces, cer_score, data_path=data_path)\n",
    "train_cer_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, val_cer_value = evaluate_model(model, processor, val_dataset.dataset.indeces, cer_score, data_path=data_path)\n",
    "val_cer_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, test_cer_value = evaluate_model(model, processor, test_dataset.dataset.indeces, cer_score, data_path=data_path)\n",
    "test_cer_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. Inference on images from train, valid and test datasets__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_fold = os.path.join(data_path, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = train_dataset.dataset.indeces[5]\n",
    "\n",
    "img, text = inference(f'{image_fold}/image_{idx}.png', model, processor)\n",
    "print(text)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = val_dataset.dataset.indeces[9]\n",
    "\n",
    "img, text = inference(f'{image_fold}/image_{idx}.png', model, processor)\n",
    "print(text)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = test_dataset.dataset.indeces[4]\n",
    "\n",
    "img, text = inference(f'{image_fold}/image_{idx}.png', model, processor)\n",
    "print(text)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5. Inference on new images__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_fold = os.path.join(project_root, 'test_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, text = inference(f'{image_fold}/test_screen.png', model, processor)\n",
    "print(text)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, text = inference(f'{image_fold}/one_channel_image.jpg', model, processor)\n",
    "print(text)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, text = inference(f'{image_fold}/test_screen_2.png', model, processor)\n",
    "print(text)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, text = inference(f'{image_fold}/a.png', model, processor)\n",
    "print(text)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, text = inference(f'{image_fold}/bred.png', model, processor)\n",
    "print(text)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
